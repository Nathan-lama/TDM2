import os
import requests
import time
import logging
import json
from pymongo import MongoClient
from pyspark.sql import SparkSession
from PIL import Image
from io import BytesIO
import hashlib
import traceback

# Remplacer l'import MongoDB par notre connecteur robuste
from db_connector import get_database

# Configuration du logger
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger('image_downloader')

# ID du worker (attribu√© par docker-compose)
WORKER_ID = int(os.environ.get('WORKER_ID', 1))
logger.info(f"D√©marrage du t√©l√©chargeur d'images (Worker ID: {WORKER_ID})")

# Configuration MongoDB
DB_URL = os.environ.get('DATABASE_URL')
client = MongoClient(DB_URL)
db = client.get_database()

# Configuration Spark
spark = SparkSession.builder \
    .appName(f"ImageDownloader-{WORKER_ID}") \
    .config("spark.driver.memory", "512m") \
    .getOrCreate()

def download_image_simple(url):
    """Version simplifi√©e qui ne capture pas d'objets non-s√©rialisables"""
    try:
        # G√©n√©rer un ID unique bas√© sur l'URL
        image_id = hashlib.md5(url.encode()).hexdigest()
        
        # Sauvegarder l'image dans le volume partag√©
        img_path = f"/data/images/{image_id}.jpg"
        
        # Configuration des headers pour √©viter les blocages
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'image/avif,image/webp,image/apng,image/*,*/*;q=0.8'
        }
        
        # T√©l√©chargement de l'image
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        
        # V√©rifier que le contenu est bien une image
        content_type = response.headers.get('Content-Type', '')
        if not content_type.startswith('image/'):
            logger.warning(f"Type de contenu non reconnu comme image: {content_type} pour {url}")
        
        # Sauvegarder l'image brute
        with open(img_path, 'wb') as f:
            f.write(response.content)
        
        # V√©rifier que l'image est valide en l'ouvrant avec PIL
        img = Image.open(img_path)
        # Force conversion to RGB if necessary
        if img.mode not in ('RGB', 'RGBA'):
            img = img.convert('RGB')
            img.save(img_path)
        
        # R√©cup√©rer les m√©tadonn√©es sans MongoDB
        metadata = {
            "_id": image_id,
            "url": url,
            "path": img_path,
            "format": img.format,
            "mode": img.mode,
            "width": img.width,
            "height": img.height,
            "orientation": "landscape" if img.width > img.height else 
                          "portrait" if img.height > img.width else "square",
            "size_bytes": len(response.content),
            "downloaded_at": time.time(),
            "downloaded_by": f"worker_{WORKER_ID}",
            "tagged": False,
            "source": "wikidata"
        }
        
        logger.info(f"Image t√©l√©charg√©e avec succ√®s: {url} -> {img_path}")
        return (True, metadata)
        
    except Exception as e:
        logger.error(f"Erreur lors du t√©l√©chargement de {url}: {e}")
        # Nettoyer les fichiers partiels en cas d'erreur
        if 'img_path' in locals() and os.path.exists(img_path):
            try:
                os.remove(img_path)
            except:
                pass
        return (False, {"url": url, "error": str(e)})

def clean_database():
    """Nettoie la base de donn√©es des anciennes images et t√¢ches"""
    try:
        # Supprimer toutes les images existantes de la base de donn√©es
        image_count = db.images.count_documents({})
        db.images.delete_many({})
        logger.info(f"Supprim√© {image_count} images de la base de donn√©es")
        
        # Supprimer les anciennes t√¢ches
        task_count = db.download_tasks.count_documents({})
        db.download_tasks.delete_many({})
        logger.info(f"Supprim√© {task_count} t√¢ches de t√©l√©chargement")
        
        # Supprimer les tags et recommandations
        db.tags.delete_many({})
        db.tagging_tasks.delete_many({})
        db.recommendation_tasks.delete_many({})
        db.recommendations.delete_many({})
        
        # Nettoyer le dossier d'images
        image_dir = "/data/images"
        if os.path.exists(image_dir):
            for filename in os.listdir(image_dir):
                file_path = os.path.join(image_dir, filename)
                try:
                    if os.path.isfile(file_path):
                        os.remove(file_path)
                except Exception as e:
                    logger.error(f"Erreur lors de la suppression du fichier {file_path}: {e}")
        
        return True
    except Exception as e:
        logger.error(f"Erreur lors du nettoyage de la base de donn√©es: {e}")
        return False

# Fonction am√©lior√©e pour se connecter √† MongoDB avec retry
def get_database_connection(max_retries=5, base_delay=1):
    """√âtablit une connexion √† la base de donn√©es avec m√©canisme de retry"""
    retry_count = 0
    last_exception = None
    
    while retry_count < max_retries:
        try:
            # Tentative de connexion
            client = MongoClient(DB_URL, serverSelectionTimeoutMS=5000)
            # V√©rifier explicitement la connexion
            client.admin.command('ping')
            logger.info("‚úÖ Connexion √† MongoDB √©tablie avec succ√®s")
            return client
        except Exception as e:
            last_exception = e
            retry_count += 1
            
            # Calcul du d√©lai avec backoff exponentiel
            delay = base_delay * (2 ** (retry_count - 1))
            
            logger.warning(f"‚ö†Ô∏è Tentative {retry_count}/{max_retries} √©chou√©e: {str(e)}")
            logger.info(f"Nouvelle tentative dans {delay} secondes...")
            
            # Attendre avant de r√©essayer
            time.sleep(delay)
    
    logger.error(f"‚ùå Impossible de se connecter √† MongoDB apr√®s {max_retries} tentatives: {last_exception}")
    raise last_exception

# Fonction pour effectuer des op√©rations MongoDB avec gestion des erreurs
def safe_db_operation(operation_func, max_retries=3):
    """Ex√©cute une op√©ration MongoDB avec gestion des erreurs et reconnexion si n√©cessaire"""
    retry_count = 0
    while retry_count < max_retries:
        try:
            return operation_func()
        except pymongo.errors.ServerSelectionTimeoutError as e:
            retry_count += 1
            if retry_count >= max_retries:
                logger.error(f"‚ùå √âchec d√©finitif de l'op√©ration apr√®s {max_retries} tentatives")
                raise
            
            logger.warning(f"‚ö†Ô∏è Erreur de connexion √† MongoDB: {e}")
            logger.info(f"Tentative de reconnexion ({retry_count}/{max_retries})...")
            
            # Tentative de reconnexion
            try:
                global client, db
                client = get_database_connection()
                db = client.get_database()
                logger.info("‚úÖ Reconnexion √† MongoDB r√©ussie")
            except Exception as reconnect_error:
                logger.error(f"‚ùå √âchec de reconnexion: {reconnect_error}")
            
            # Attendre avant de r√©essayer l'op√©ration
            time.sleep(2)
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'op√©ration MongoDB: {e}")
            raise

# Remplacer les appels directs √† la base de donn√©es par des versions s√©curis√©es
def process_task():
    """Traitement des t√¢ches avec gestion robuste des erreurs de connexion"""
    try:
        # Recherche d'une t√¢che de nettoyage avec gestion d'erreurs
        def find_clean_task():
            return db.download_tasks.find_one({"worker_id": WORKER_ID, "action": "clean", "status": "pending"})
        
        clean_task = safe_db_operation(find_clean_task)
        
        if clean_task:
            logger.info("T√¢che de nettoyage d√©tect√©e. Nettoyage de la base de donn√©es...")
            success = clean_database()
            db.download_tasks.update_one(
                {"_id": clean_task["_id"]},
                {"$set": {
                    "status": "completed" if success else "failed",
                    "completed_at": time.time()
                }}
            )
            return True
            
        # Recherche d'une t√¢che de t√©l√©chargement avec gestion d'erreurs
        def find_download_task():
            return db.download_tasks.find_one({"worker_id": WORKER_ID, "status": "pending"})
            
        task = safe_db_operation(find_download_task)
        
        if task:
            urls = task.get("urls", [])
            if not urls:
                logger.warning(f"T√¢che trouv√©e pour le Worker {WORKER_ID} mais sans URLs")
                return False
            
            logger.info(f"Traitement de {len(urls)} URLs pour le Worker {WORKER_ID}")
            
            # Utilisation de PySpark pour traiter les URLs
            urls_rdd = spark.sparkContext.parallelize(urls)
            
            # Utilisation d'une fonction qui ne capture pas d'objets non-s√©rialisables
            results = urls_rdd.map(download_image_simple).collect()
            
            # Traiter les r√©sultats apr√®s que Spark a fait son travail
            success_count = 0
            for success, metadata in results:
                if success:
                    # Maintenant nous pouvons utiliser MongoDB en toute s√©curit√©
                    db.images.update_one(
                        {"_id": metadata["_id"]},
                        {"$set": metadata},
                        upsert=True
                    )
                    success_count += 1
                else:
                    logger.error(f"Erreur lors du t√©l√©chargement de {metadata['url']}: {metadata.get('error')}")
            
            # Mettre √† jour le statut de la t√¢che
            db.download_tasks.update_one(
                {"_id": task["_id"]},
                {"$set": {
                    "status": "completed",
                    "completed_at": time.time(),
                    "success_count": success_count,
                    "total_count": len(urls)
                }}
            )
            
            logger.info(f"T√¢che compl√©t√©e: {success_count}/{len(urls)} images t√©l√©charg√©es avec succ√®s")
            return True
        else:
            logger.info(f"Aucune t√¢che trouv√©e pour le Worker {WORKER_ID}")
            logger.info("En attente de nouvelles t√¢ches...")
            return False
            
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du traitement des t√¢ches: {e}")
        logger.error(traceback.format_exc())
        time.sleep(10)  # Attente plus longue en cas d'erreur grave
        return False

# Initialisation avec la nouvelle fonction de connexion r√©siliente
def main():
    global client, db
    
    logger.info(f"üöÄ D√©marrage du worker image_downloader {WORKER_ID}")
    
    try:
        # √âtablir la connexion initiale avec gestion des erreurs
        client = get_database_connection(max_retries=10, base_delay=2)
        db = client.get_database()
        
        while True:
            task_processed = process_task()
            
            # Petit d√©lai si aucune t√¢che n'a √©t√© trait√©e
            if not task_processed:
                time.sleep(60)  # Une minute d'attente entre les v√©rifications
            else:
                # Temps de repos court entre les t√¢ches
                time.sleep(1)
                
    except KeyboardInterrupt:
        logger.info("Arr√™t du worker")
    except Exception as e:
        logger.critical(f"‚ùå Erreur fatale: {e}")
        logger.critical(traceback.format_exc())
        raise

if __name__ == "__main__":
    main()
